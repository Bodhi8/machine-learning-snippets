{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "import pprint\n",
      "documents = [\"Human machine interface for lab abc computer applications\",\n",
      "              \"A survey of user opinion of computer system response time\",\n",
      "              \"The EPS user interface management system\",\n",
      "              \"System and human system engineering testing of EPS\",\n",
      "              \"Relation of user perceived response time to error measurement\",\n",
      "              \"The generation of random binary unordered trees\",\n",
      "              \"The intersection graph of paths in trees\",\n",
      "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
      "              \"Graph minors A survey\"]\n",
      "pprint.pprint(documents) #a simple list representation."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Human machine interface for lab abc computer applications',\n",
        " 'A survey of user opinion of computer system response time',\n",
        " 'The EPS user interface management system',\n",
        " 'System and human system engineering testing of EPS',\n",
        " 'Relation of user perceived response time to error measurement',\n",
        " 'The generation of random binary unordered trees',\n",
        " 'The intersection graph of paths in trees',\n",
        " 'Graph minors IV Widths of trees and well quasi ordering',\n",
        " 'Graph minors A survey']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove common words and tokenize (lowercase the beginning of the word and split at whitespaces)\n",
      "stoplist = set('for a of the and to in'.split())\n",
      "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
      "          for document in documents]\n",
      "\n",
      "# remove words that appear only once\n",
      "all_tokens = sum(texts)\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "texts = [[word for word in text if word not in tokens_once]\n",
      "          for text in texts]\n",
      "\n",
      "pprint.pprint(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['human', 'interface', 'computer'],\n",
        " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
        " ['eps', 'user', 'interface', 'system'],\n",
        " ['system', 'human', 'system', 'eps'],\n",
        " ['user', 'response', 'time'],\n",
        " ['trees'],\n",
        " ['graph', 'trees'],\n",
        " ['graph', 'minors', 'trees'],\n",
        " ['graph', 'minors', 'survey']]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Bag of words representation\n",
      "dict1 = corpora.Dictionary(texts)\n",
      "dict1.save('./deerwester.dict') #saving in current working directory\n",
      "print dict1\n",
      "pprint.pprint(dict1.token2id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(12 unique tokens: ['minors', 'graph', 'system', 'trees', 'eps']...)\n",
        "{'computer': 0,\n",
        " 'eps': 8,\n",
        " 'graph': 10,\n",
        " 'human': 1,\n",
        " 'interface': 2,\n",
        " 'minors': 11,\n",
        " 'response': 3,\n",
        " 'survey': 4,\n",
        " 'system': 5,\n",
        " 'time': 6,\n",
        " 'trees': 9,\n",
        " 'user': 7}\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_doc = \"Human Computer Trees Interaction\"\n",
      "new_vec = dict1.doc2bow(new_doc.lower().split())#.doct2bow: document to bag of words, do the same tokenization as before (repeated here)\n",
      "print(new_vec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 1), (1, 1), (9, 1)]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dict1.doc2bow(text) for text in texts]\n",
      "pprint.pprint(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[(0, 1), (1, 1), (2, 1)],\n",
        " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
        " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
        " [(1, 1), (5, 2), (8, 1)],\n",
        " [(3, 1), (6, 1), (7, 1)],\n",
        " [(9, 1)],\n",
        " [(9, 1), (10, 1)],\n",
        " [(9, 1), (10, 1), (11, 1)],\n",
        " [(4, 1), (10, 1), (11, 1)]]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpora.MmCorpus.serialize('./deerwester.mm', corpus) # store to disk, for later use"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Aside: two ways to count words: defaultdict or without\n",
      "# from collections import defaultdict\n",
      "# wordsFreq = defaultdict(int)\n",
      "# while True:\n",
      "#     word = raw_input()\n",
      "#     if not word:\n",
      "#         break\n",
      "#     wordsFreq[word] += 1\n",
      "# wordsFreq = {}\n",
      "# while True:\n",
      "#     word = raw_input()\n",
      "#     if not word:\n",
      "#         break\n",
      "#     wordsFreq[word] = wordFreq.get(word, 0) + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Aside: Streaming corpus\n",
      "\n",
      "class MyCorpus(object):\n",
      "    def __iter__(self):\n",
      "        for line in open('mycorpus.txt'):\n",
      "        # assume there's one document per line, tokens separated by whitespace\n",
      "            yield dictionary.doc2bow(line.lower().split())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_memory_friendly = MyCorpus() # doesn't load the corpus into memory!\n",
      "print(corpus_memory_friendly)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<__main__.MyCorpus object at 0x1064b7390>\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for vec1 in corpus_memory_friendly:\n",
      "    print vec1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'dictionary' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-24-7743dda7bb27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvec1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus_memory_friendly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mvec1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-20-6fbcf238ca7f>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mycorpus.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# assume there's one document per line, tokens separated by whitespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: global name 'dictionary' is not defined"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}