{
 "metadata": {
  "name": "Theano-tutorial-Logistic-Regression"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Part 3\n",
      "#source: http://deeplearning.net/software/theano/tutorial/examples.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#imports\n",
      "import numpy as np\n",
      "from theano import function, shared\n",
      "import theano.tensor as T\n",
      "\n",
      "#Data and some parameters\n",
      "rng = np.random\n",
      "N = 4000\n",
      "feats = 20\n",
      "D = (rng.randn(N/2, feats)+[[zzz+1 for zzz in zz] for zz in rng.randn(N/2, feats)], \\\n",
      "        np.asarray([0]*(N/2) + [1]*(N/2)))\n",
      "training_steps = 10000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp = rng.randint(size=N, low=0, high=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "whos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variable         Type                    Data/Info\n",
        "--------------------------------------------------\n",
        "D                tuple                   n=2\n",
        "N                int                     4000\n",
        "T                module                  <module 'theano.tensor' f<...>ano/tensor/__init__.pyc'>\n",
        "b                ScalarSharedVariable    b\n",
        "cost             TensorVariable          Elemwise{add,no_inplace}.0\n",
        "err              ndarray                 4000: 4000 elems, type `float64`, 32000 bytes\n",
        "feats            int                     20\n",
        "function         function                <function function at 0x106b7fed8>\n",
        "gb               TensorVariable          DimShuffle{}.0\n",
        "gw               TensorVariable          Elemwise{add,no_inplace}.0\n",
        "i                int                     0\n",
        "p_1              TensorVariable          Elemwise{true_div,no_inplace}.0\n",
        "pred             ndarray                 4000: 4000 elems, type `int8`, 4000 bytes\n",
        "predict          Function                <theano.compile.function_<...>on object at 0x117881250>\n",
        "prediction       TensorVariable          Elemwise{gt,no_inplace}.0\n",
        "rng              module                  <module 'numpy.random' fr<...>mpy/random/__init__.pyc'>\n",
        "shared           function                <function shared at 0x106b1e848>\n",
        "temp             ndarray                 4000: 4000 elems, type `int64`, 32000 bytes\n",
        "train            Function                <theano.compile.function_<...>on object at 0x1063e7a90>\n",
        "training_steps   int                     10000\n",
        "w                TensorSharedVariable    w\n",
        "x                TensorVariable          x\n",
        "xent             TensorVariable          Elemwise{sub,no_inplace}.0\n",
        "y                TensorVariable          y\n",
        "z1               int8                    1\n",
        "z2               int64                   1\n",
        "zz               ndarray                 20: 20 elems, type `float64`, 160 bytes\n",
        "zzz              float64                 -1.23414214021\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Declare Theano symbolic variables\n",
      "x = T.matrix(\"x\")#feature matrix\n",
      "y = T.vector(\"y\")#labels\n",
      "w = shared(rng.randn(feats), name=\"w\")#shared symbol: linear weights which are randomly initialized\n",
      "b = shared(0., name=\"b\")#shared symbol: intercept\n",
      "print \"Initial model:\"\n",
      "print w.get_value(), b.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initial model:\n",
        "[ 1.38980671 -0.0211797  -1.67677107  1.53016202  0.04458027 -0.52230184\n",
        " -0.87127673  1.13787423  0.79205566  0.10950088  0.07608564  1.48539296\n",
        " -0.05646129  1.246218   -1.38890484 -0.92075408  1.4630561  -0.84211374\n",
        "  0.16704903  0.04701836] 0.0\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construct Theano expression graph\n",
      "\n",
      "#we will do a l2 regularized logistic regression here\n",
      "#the training loss function will be the E_{data}[- log likelihood]\n",
      "\n",
      "p_1 = 1 / (1 + T.exp(-T.dot(x, w) - b))   # Probability that target = 1\n",
      "prediction = p_1 > 0.5                    # The prediction thresholded\n",
      "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss function\n",
      "cost = xent.mean() + 0.01 * (w ** 2).sum()# The cost to minimize\n",
      "\n",
      "gw, gb = T.grad(cost, [w, b])             # Compute the gradient of the cost\n",
      "                                          # (we shall return to this in a\n",
      "                                          # following section of this tutorial)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compile\n",
      "train = function(\n",
      "          inputs=[x,y],\n",
      "          outputs=[prediction, xent],\n",
      "          updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))\n",
      "predict = function(inputs=[x], outputs=prediction)\n",
      "\n",
      "# Train\n",
      "for i in range(training_steps):\n",
      "    pred, err = train(D[0], D[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Input dimension mis-match. (input[0].shape[0] = 4000, input[1].shape[0] = 2000)\nApply node that caused the error: Elemwise{Composite{[Composite{[Composite{[sub(mul(i0, i1), neg(i2))]}(i0, scalar_softplus(i1), mul(i2, i3))]}(i0, i1, i2, scalar_softplus(i3))]}}(y, Elemwise{Composite{[sub(neg(i0), i1)]}}[(0, 0)].0, Elemwise{sub,no_inplace}.0, Elemwise{neg,no_inplace}.0)\nInputs shapes: [(4000,), (2000,), (4000,), (2000,)]\nInputs strides: [(8,), (8,), (8,), (8,)]\nInputs types: [TensorType(float64, vector), TensorType(float64, vector), TensorType(float64, vector), TensorType(float64, vector)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-42-4d6056d7b08b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/theja/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m                     \u001b[0;31m# For the CVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                     gof.vm.raise_with_op(self.fn.nodes[self.fn.position_of_error],\n\u001b[0;32m--> 588\u001b[0;31m                                          self.fn.thunks[self.fn.position_of_error])\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0;31m# For the c linker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/theja/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[0] = 4000, input[1].shape[0] = 2000)\nApply node that caused the error: Elemwise{Composite{[Composite{[Composite{[sub(mul(i0, i1), neg(i2))]}(i0, scalar_softplus(i1), mul(i2, i3))]}(i0, i1, i2, scalar_softplus(i3))]}}(y, Elemwise{Composite{[sub(neg(i0), i1)]}}[(0, 0)].0, Elemwise{sub,no_inplace}.0, Elemwise{neg,no_inplace}.0)\nInputs shapes: [(4000,), (2000,), (4000,), (2000,)]\nInputs strides: [(8,), (8,), (8,), (8,)]\nInputs types: [TensorType(float64, vector), TensorType(float64, vector), TensorType(float64, vector), TensorType(float64, vector)]\nUse the Theano flag 'exception_verbosity=high' for a debugprint of this apply node."
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Final model:\"\n",
      "print w.get_value(), b.get_value()\n",
      "#print \"(predicted,target) values for D:\", zip(predict(D[0]),D[1])\n",
      "print \"in sample error:\", 1.0*sum([z1==z2 for (z1,z2) in zip(predict(D[0]),D[1])])/N"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Final model:\n",
        "[ 0.00393401  0.00941731 -0.0425401   0.05276637 -0.02440124  0.00627808\n",
        " -0.00357578  0.00933039  0.03702086  0.02646278  0.01284875 -0.04593336\n",
        "  0.01007222 -0.00748024  0.0300843  -0.01940728 -0.01338306  0.02231058\n",
        "  0.00113928 -0.00503293] -0.046518957407\n",
        "in sample error: 0.52275\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}